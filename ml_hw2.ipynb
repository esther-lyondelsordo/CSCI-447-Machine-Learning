{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b624b3f9",
   "metadata": {},
   "source": [
    "<h1>Machine Learning Homework #2</h1>\n",
    "\n",
    "**Esther Lyon Delsordo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d16d2210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c713fef9",
   "metadata": {},
   "source": [
    "<h2>Problem 1: Full Bayesian Inference</h2>\n",
    "We have seen that we can estimate the maximum likelihood estimators for a variety of distributions from\n",
    "some observations. However it is also possible to infer full posterior distributions, rather than just point\n",
    "estimators for some useful cases.\n",
    "Coin flips\n",
    "Consider first the problem of trying to infer the weighted-ness $\\theta$ of a coin. In particular, use Bayes’ theorem\n",
    "to show that the posterior distribution\n",
    "$$P(\\theta|X)$$\n",
    "is Beta-distributed, assuming that the likelihood \n",
    "$$P(X|\\theta) = \\prod^m_{i=1} Bernoulli(X_i; \\theta)$$ \n",
    "is independent and Bernoulli distributed and the prior $P(\\theta) = Beta(\\theta; α, β)$ is Beta-distributed with known hyperparameters $α$ and $β$. \n",
    "(If you don’t know where to start with this: first, look up the PDF for a beta distribution, which you should use\n",
    "for the prior. Multiply it with the likelihood function. Collect terms and perhaps rename these collections\n",
    "so that the resulting posterior again has the PDF of a beta distribution).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3216bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba04bddb",
   "metadata": {},
   "source": [
    "<h2>Problem 2: Feature augmentation</h2>\n",
    "<h3>(a)</h3>\n",
    "Suppose that you have a dataset that looks like Figure 1, and you would to perform linear regression on it.\n",
    "Describe your approach for constructing a design matrix $\\Phi$ for this problem. Specifically, what would you place in each of the columns of $\\Phi$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "964b886b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Fig2_2a.png\" width=\"600\" alt=\"Figure 2a\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(alt=\"Figure 2a\", url=\"Fig2_2a.png\", width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a23eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6aa51a47",
   "metadata": {},
   "source": [
    "<h3>(b)</h3> Same question as above. Would the same approach that you used in Part 1, also work here? Why or why\n",
    "not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "055d6bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Fig2_2b.png\" width=\"600\" alt=\"Figure 2b\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(alt=\"Figure 2b\", url=\"Fig2_2b.png\", width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efed7c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77fc778c",
   "metadata": {},
   "source": [
    "<h2>Problem 3: Gradient Descent</h2>\n",
    "<h3>(a)</h3>\n",
    "Consider the function\n",
    "$$\\mathcal{L}(\\vec \\theta) = \\frac{1}{2}(\\theta_1^2 - \\theta_2)^2 + \\frac{1}{2}(\\theta_1 - 1)^2$$\n",
    "Derive an expression for the gradient of this function with respect to ~θ. Implement some code that uses\n",
    "gradient descent to find its minimum value. Create a plot similar to those we did in class that illustrates\n",
    "your algorithm’s progress to this minimum beginning from at least 3 randomly selected initial positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f082e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1b0742c",
   "metadata": {},
   "source": [
    "<h3>(c)</h3>\n",
    "Describe, as specifically as you can, why it is not possible to solve directly for the minimum values of the\n",
    "functions that you worked with above. Describe how this relates to logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45be9b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
